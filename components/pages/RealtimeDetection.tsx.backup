"use client";

import React, { useRef, useEffect, useState } from "react";
import { Card } from "@/components/ui/card";
import {
  Select,
  SelectContent,
  SelectItem,
  SelectTrigger,
  SelectValue,
} from "@/components/ui/select";
import {
  preprocessVideoForSSD,
  parseSSDOutput,
  drawDetections,
} from "@/lib/ssd-detector";

// Type for ONNX Runtime
type OrtType = typeof import("onnxruntime-web");

// The actual InferenceSession instance type (what create() returns)
// This has properties that aren't in the InferenceSessionFactory type
type InferenceSessionInstance = {
  readonly inputNames: readonly string[];
  readonly outputNames: readonly string[];
  run(
    feeds: Record<string, InstanceType<OrtType["Tensor"]>>
  ): Promise<Record<string, InstanceType<OrtType["Tensor"]>>>;
};

export default function RealtimeDetection() {
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const [session, setSession] = useState<InferenceSessionInstance | null>(null);
  const [isLoading, setIsLoading] = useState(true);
  const [error, setError] = useState<string | null>(null);
  const [isMounted, setIsMounted] = useState(false);
  const [ort, setOrt] = useState<OrtType | null>(null);
  const [modelInfo, setModelInfo] = useState<string | null>(null);
  const [fps, setFps] = useState<number>(0);
  const [detectionCount, setDetectionCount] = useState<number>(0);
  const [inferenceInterval, setInferenceInterval] = useState<number>(1000); // Default: 1 second
  const lastInferenceTimeRef = useRef<number>(0);
  const [lastDetections, setLastDetections] = useState<
    ReturnType<typeof parseSSDOutput>
  >([]);

  // Ensure we're on client side
  useEffect(() => {
    setIsMounted(true);
  }, []);

  // Dynamically import onnxruntime-web on client side only
  useEffect(() => {
    if (!isMounted || typeof window === "undefined") return;

    async function loadOnnxRuntime() {
      try {
        console.log("Loading ONNX Runtime Web...");
        const ortModule = await import("onnxruntime-web");
        setOrt(ortModule);
        console.log("ONNX Runtime Web loaded successfully");
      } catch (e) {
        // Suppress error overlay by using console.warn instead of console.error
        const errorMessage = e instanceof Error ? e.message : "Unknown error";
        console.warn("Failed to load ONNX Runtime Web:", errorMessage);
        setError(
          "Failed to load ONNX Runtime library. Please refresh the page."
        );
        setIsLoading(false);
      }
    }

    loadOnnxRuntime();
  }, [isMounted]);

  // Load Model after ONNX Runtime is loaded
  useEffect(() => {
    if (!ort) return;

    const ortRuntime = ort; // Create local constant for type safety

    async function loadModel() {
      try {
        // Configure ONNX Runtime Web environment
        if (ortRuntime.env?.wasm) {
          ortRuntime.env.wasm.wasmPaths =
            "https://cdn.jsdelivr.net/npm/onnxruntime-web@1.23.2/dist/";
          // Suppress CPU vendor warning (harmless warning about unknown CPU)
          ortRuntime.env.wasm.numThreads = 1;
        }

        // Set log level to warning to reduce console noise
        ortRuntime.env.logLevel = "warning";

        console.log("Loading ONNX model from /models/ssd_mobilenet.onnx...");

        // NOTE: You may see a warning "Unknown CPU vendor" in the console.
        // This is HARMLESS and EXPECTED - see docs/ONNX_CPU_WARNING.md for details.
        // The warning comes from ONNX Runtime's internal code and cannot be suppressed.
        // Your model will still load and run correctly.
        const sess = await ortRuntime.InferenceSession.create(
          "/models/ssd_mobilenet.onnx",
          {
            // Try WebGL first, then fallback to WASM and CPU
            executionProviders: ["webgl", "wasm", "cpu"],
          }
        );

        console.log("âœ… Model loaded successfully!");

        // Log which execution provider is being used
        console.log("ðŸš€ Model ready - Inference session created");
        console.log("ï¿½ Model inputs:", sess.inputNames);
        console.log("ðŸ“Š Model outputs:", sess.outputNames);

        // Set model info for UI display
        setModelInfo(
          `Model loaded with ${sess.inputNames.length} input(s) and ${sess.outputNames.length} output(s)`
        );

        setSession(sess as InferenceSessionInstance);
        setIsLoading(false);
      } catch (e) {
        // Suppress error overlay by using console.warn and extracting message only
        const errorMessage =
          e instanceof Error ? e.message : "Unknown error loading model";
        console.warn("âŒ Failed to load model:", errorMessage);
        setError(errorMessage);
        setIsLoading(false);
      }
    }

    loadModel();
    startCamera(); // Keep startCamera here as it was originally in the model loading effect
  }, [ort]);

  // 2. Akses Kamera
  const startCamera = async () => {
    if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: "environment" }, // Kamera belakang untuk HP
        audio: false,
      });
      if (videoRef.current) {
        videoRef.current.srcObject = stream;
      }
    }
  };

  // 3. Loop Deteksi Real-time
  useEffect(() => {
    if (!session || !ort) return;

    let requestID: number;
    let isProcessing = false;
    let lastTime = performance.now();
    let frameCount = 0;

    const detectFrame = async () => {
      const now = performance.now();

      if (
        videoRef.current &&
        canvasRef.current &&
        session &&
        !isProcessing &&
        videoRef.current.readyState === 4 &&
        now - lastInferenceTimeRef.current >= inferenceInterval // Throttle based on selected interval
      ) {
        const video = videoRef.current;
        const canvas = canvasRef.current;
        const ctx = canvas.getContext("2d");

        if (!ctx) {
          requestID = requestAnimationFrame(detectFrame);
          return;
        }

        isProcessing = true;
        lastInferenceTimeRef.current = now; // Update last inference time
        const startTime = performance.now();

        try {
          // Samakan ukuran canvas dengan video
          canvas.width = video.videoWidth;
          canvas.height = video.videoHeight;

          // Gambar video ke canvas
          ctx.clearRect(0, 0, canvas.width, canvas.height);
          ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

          // --- Preprocessing untuk SSD MobileNet ---
          const inputTensor = preprocessVideoForSSD(video, 300);

          // --- Run Inference ---
          const inputName = session.inputNames[0];
          const feeds = { [inputName]: inputTensor };
          const outputs = await session.run(feeds);

          // Debug: Log output structure (only on first detection)
          if (frameCount === 0) {
            console.log("ðŸ” Model outputs:", Object.keys(outputs));
            Object.entries(outputs).forEach(([name, tensor]) => {
              console.log(
                `  - ${name}: shape=${tensor.dims}, type=${tensor.type}`
              );
            });
          }

          // --- Parse hasil deteksi ---
          const detections = parseSSDOutput(
            outputs,
            0.5, // threshold confidence
            canvas.width,
            canvas.height
          );

          // Update detection count
          setDetectionCount(detections.length);

          // --- Gambar bounding boxes ---
          drawDetections(ctx, detections);

          // Calculate FPS
          frameCount++;
          const currentTime = performance.now();
          if (currentTime - lastTime >= 1000) {
            setFps(frameCount);
            frameCount = 0;
            lastTime = currentTime;
          }

          // Log deteksi (optional, untuk debugging)
          if (detections.length > 0) {
            console.log(`Detected ${detections.length} object(s):`, detections);
          }
        } catch (error) {
          // Suppress error overlay - only log message, not full error object
          const errorMessage =
            error instanceof Error ? error.message : "Unknown detection error";
          console.warn("Error during detection:", errorMessage);
        } finally {
          isProcessing = false;
        }
      }

      requestID = requestAnimationFrame(detectFrame);
    };

    detectFrame();
    return () => cancelAnimationFrame(requestID);
  }, [session, ort, inferenceInterval]); // Added inferenceInterval to restart loop when changed

  return (
    <Card className="p-4 flex flex-col items-center">
      <h2 className="text-xl font-bold mb-4">Deteksi Realtime</h2>
      {isLoading && <p className="text-blue-600">Memuat Model...</p>}
      {error && (
        <div className="bg-red-50 border border-red-200 text-red-700 px-4 py-3 rounded mb-4">
          <p className="font-bold">Error loading model:</p>
          <p className="text-sm">{error}</p>
        </div>
      )}
      {modelInfo && !isLoading && !error && (
        <div className="bg-green-50 border border-green-200 text-green-700 px-4 py-3 rounded mb-4">
          <p className="text-sm">âœ… {modelInfo}</p>
        </div>
      )}

      {/* Performance Stats */}
      {session && !isLoading && (
        <div className="bg-blue-50 border border-blue-200 text-blue-700 px-4 py-2 rounded mb-4 flex gap-4 text-sm">
          <div>
            <span className="font-bold">FPS:</span> {fps}
          </div>
          <div>
            <span className="font-bold">Detections:</span> {detectionCount}
          </div>
        </div>
      )}

      {/* Interval Control */}
      {session && !isLoading && (
        <div className="w-full max-w-[640px] mb-4">
          <label className="block text-sm font-medium mb-2">
            Interval Prediksi
          </label>
          <Select
            value={inferenceInterval.toString()}
            onValueChange={(value) => setInferenceInterval(Number(value))}
          >
            <SelectTrigger className="w-full">
              <SelectValue placeholder="Pilih interval prediksi" />
            </SelectTrigger>
            <SelectContent>
              <SelectItem value="1000">1 detik</SelectItem>
              <SelectItem value="2000">2 detik</SelectItem>
              <SelectItem value="3000">3 detik</SelectItem>
              <SelectItem value="4000">4 detik</SelectItem>
              <SelectItem value="5000">5 detik</SelectItem>
            </SelectContent>
          </Select>
          <p className="text-xs text-muted-foreground mt-1">
            Model akan melakukan prediksi setiap {inferenceInterval / 1000}{" "}
            detik
          </p>
        </div>
      )}

      <div className="relative">
        <video
          ref={videoRef}
          autoPlay
          muted
          playsInline
          className="rounded-lg shadow-lg"
          style={{ width: "100%", maxWidth: "640px" }}
        />
        <canvas
          ref={canvasRef}
          className="absolute top-0 left-0 rounded-lg"
          style={{ width: "100%", maxWidth: "640px" }}
        />
      </div>
    </Card>
  );
}
